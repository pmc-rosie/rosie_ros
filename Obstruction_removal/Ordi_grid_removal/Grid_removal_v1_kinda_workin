import cv2
import numpy as np

# List of all part image paths
part_paths = [
    '/Users/etiennechoquette/Documents/Ecole/ROSIE/Code/rosie_ros/Obstruction_removal/Ordi_grid_removal/Test_Ordi/part_1.jpeg',
    '/Users/etiennechoquette/Documents/Ecole/ROSIE/Code/rosie_ros/Obstruction_removal/Ordi_grid_removal/Test_Ordi/part_2.jpeg',
    '/Users/etiennechoquette/Documents/Ecole/ROSIE/Code/rosie_ros/Obstruction_removal/Ordi_grid_removal/Test_Ordi/part_3.jpeg',
    '/Users/etiennechoquette/Documents/Ecole/ROSIE/Code/rosie_ros/Obstruction_removal/Ordi_grid_removal/Test_Ordi/part_4.jpeg',
    '/Users/etiennechoquette/Documents/Ecole/ROSIE/Code/rosie_ros/Obstruction_removal/Ordi_grid_removal/Test_Ordi/part_5.jpeg',
    '/Users/etiennechoquette/Documents/Ecole/ROSIE/Code/rosie_ros/Obstruction_removal/Ordi_grid_removal/Test_Ordi/part_6.jpeg'
]

# Load the part images
parts = []
for path in part_paths:
    image = cv2.imread(path)
    if image is not None:
        parts.append(image)
    else:
        print(f"Warning: Unable to load image at {path}")

# Load the reference image
reference_image_path = '/Users/etiennechoquette/Documents/Ecole/ROSIE/Code/rosie_ros/Obstruction_removal/Ordi_grid_removal/Test_Ordi/reference.jpeg'
reference_image = cv2.imread(reference_image_path)
if reference_image is None:
    raise ValueError("Reference image not found")

# Function to align two images using SIFT feature matching and homography
def align_images(reference_img, img_to_align):
    # Convert images to grayscale
    ref_gray = cv2.cvtColor(reference_img, cv2.COLOR_BGR2GRAY)
    align_gray = cv2.cvtColor(img_to_align, cv2.COLOR_BGR2GRAY)
    
    # Detect SIFT keypoints and descriptors
    sift = cv2.SIFT_create(nfeatures=5000)
    kp1, des1 = sift.detectAndCompute(ref_gray, None)
    kp2, des2 = sift.detectAndCompute(align_gray, None)
    
    # Use FLANN based matcher for better performance and robustness
    FLANN_INDEX_KDTREE = 1
    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
    search_params = dict(checks=50)
    flann = cv2.FlannBasedMatcher(index_params, search_params)
    matches = flann.knnMatch(des1, des2, k=2)
    
    # Store all the good matches as per Lowe's ratio test.
    good_matches = []
    for m, n in matches:
        if m.distance < 0.6 * n.distance:
            good_matches.append(m)
    
    if len(good_matches) > 10:
        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 2)
        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 2)
        
        # Find homography matrix
        H, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)
        
        # Warp img_to_align to align with reference_img
        height, width, channels = reference_img.shape
        aligned_img = cv2.warpPerspective(img_to_align, H, (width, height))
        
        return aligned_img
    else:
        print("Not enough matches are found - {}/{}".format(len(good_matches), 10))
        return img_to_align

# Align each part image with the reference image
aligned_images = [parts[0]]
for i in range(1, len(parts)):
    aligned_part = align_images(reference_image, parts[i])
    aligned_images.append(aligned_part)

# Merge the aligned images using simple averaging
result = np.zeros_like(aligned_images[0], dtype=np.float32)
for aligned_part in aligned_images:
    result += aligned_part.astype(np.float32) / len(aligned_images)

# Convert result to uint8
result = np.clip(result, 0, 255).astype(np.uint8)

# Save the final stitched image
output_path = '/Users/etiennechoquette/Documents/Ecole/ROSIE/Code/rosie_ros/Obstruction_removal/Ordi_grid_removal/Test_Ordi/final_stitched_image_accurate.jpeg'
cv2.imwrite(output_path, result)

print(f"Final stitched image saved as '{output_path}'")
